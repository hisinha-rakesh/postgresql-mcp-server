# YouTube Presentation Prompt: Enterprise PostgreSQL MCP Server

## ðŸŽ¯ Video Overview
Create a comprehensive tutorial video demonstrating how to build and use an Enterprise-level Model Context Protocol (MCP) Server for PostgreSQL that enables Claude Desktop to perform full database operations through natural language.

---

## ðŸ“‹ Presentation Structure

### 1. Introduction (2-3 minutes)
**Talking Points:**
- "Today I'll show you how to create a production-grade MCP server that gives Claude Desktop complete control over your PostgreSQL database"
- "Unlike the standard read-only MCP PostgreSQL server, this enterprise version supports full DDL, DML, and TCL operations"
- "By the end of this video, you'll be able to manage your database using natural language commands like 'Create a users table' or 'Insert 100 records'"

**What to Show:**
- Quick demo: Open Claude Desktop and say "Show me all tables in my database"
- Show Claude executing complex operations like creating tables, inserting data, and running transactions
- Highlight that all database operations happen through natural conversation

---

### 2. What is MCP? (3-4 minutes)

**Talking Points:**
- "MCP stands for Model Context Protocol - it's Anthropic's open protocol that lets AI assistants like Claude interact with external systems"
- "Think of MCP as a bridge between Claude and your tools, databases, or APIs"
- "Instead of just talking, Claude can now DO things - query databases, run commands, access files"

**Visual Diagram to Show:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Claude Desktop        â”‚
â”‚   (Natural Language)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚ MCP Protocol
            â”‚ (stdio)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   MCP Server            â”‚
â”‚   (Tool Registration)   â”‚
â”‚   (Request Routing)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚ asyncpg
            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PostgreSQL Database   â”‚
â”‚   (Azure/Local)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Concepts:**
- MCP servers expose "tools" that Claude can call
- Communication happens via stdio (standard input/output)
- Claude discovers available tools automatically
- Each tool has a name, description, and input schema

---

### 3. Project Architecture (4-5 minutes)

**Files to Explain:**

#### File 1: `mcp_server_enterprise.py` (The Core Server)
**Show on screen and explain:**
```python
# Key components to highlight:
1. DatabasePool class (lines 49-84)
   - Connection pooling for performance
   - Min 2, Max 10 connections
   - 60-second timeout

2. Tool Registration (lines 94-354)
   - 13 different tools available
   - DML: SELECT, INSERT, UPDATE, DELETE
   - DDL: CREATE TABLE, ALTER TABLE, DROP TABLE
   - TCL: TRANSACTION support
   - Utility: Schema inspection

3. Tool Handlers (lines 407-727)
   - Each tool has a handler function
   - Parameterized queries for security
   - RETURNING clause support for INSERT
   - Transaction isolation levels
```

**Explain the Tool Pattern:**
```python
Tool(
    name="execute_insert",
    description="Execute an INSERT statement to add new rows",
    inputSchema={
        "type": "object",
        "properties": {
            "query": {"type": "string"},
            "params": {"type": "array"}
        }
    }
)
```

#### File 2: `claude_desktop_config.json` (Claude Integration)
**Show configuration:**
```json
{
  "mcpServers": {
    "postgres-enterprise": {
      "command": "C:\\Users\\kusha\\postgresql-mcp\\.venv\\Scripts\\python.exe",
      "args": ["C:\\Users\\kusha\\postgresql-mcp\\mcp_server_enterprise.py"],
      "env": {
        "DATABASE_URL": "postgresql://user:pass@host:5432/db?sslmode=require"
      }
    }
  }
}
```

**Key points:**
- Absolute paths required
- Windows uses double backslashes
- DATABASE_URL passed as environment variable
- Supports multiple MCP servers

#### File 3: `.env` (Environment Configuration)
```env
DATABASE_URL=postgresql://pgadmina:Centurylink%40123@pgs-youtube-app.postgres.database.azure.com:5432/postgres?sslmode=require
```
**Important notes:**
- Special characters must be URL-encoded (@ becomes %40)
- SSL mode required for cloud databases
- Never commit this file to version control

#### File 4: `requirements.txt` (Dependencies)
```
mcp>=1.0.0              # MCP protocol SDK
asyncpg>=0.29.0         # PostgreSQL async driver
python-dotenv           # Environment variable management
fastapi                 # Optional: For REST API
requests                # For client testing
```

---

### 4. Step-by-Step Setup (10-12 minutes)

#### Step 1: PostgreSQL Database Setup (Azure)
**Show on screen:**
1. Open Azure Portal â†’ Create Azure Database for PostgreSQL
2. Configure:
   - Server name: `pgs-youtube-app`
   - Admin username: `pgadmina`
   - Password: (strong password)
   - Location: Choose nearest region
   - Compute + Storage: Basic tier for demo
3. Networking:
   - Add your IP to firewall rules
   - Enable SSL enforcement
4. Get connection string from Azure portal

**Explain:**
- "Azure provides managed PostgreSQL with automatic backups"
- "SSL is enforced for security"
- "Firewall rules control access"

#### Step 2: Local Development Setup
**Show terminal commands:**
```bash
# 1. Create project directory
mkdir postgresql-mcp
cd postgresql-mcp

# 2. Create virtual environment
python -m venv .venv

# 3. Activate virtual environment (Windows)
.venv\Scripts\activate

# 4. Install dependencies
pip install -r requirements.txt

# 5. Verify installation
pip list | grep mcp
pip list | grep asyncpg
```

**Explain each step:**
- Virtual environment isolates dependencies
- MCP SDK provides protocol implementation
- asyncpg is the high-performance PostgreSQL driver

#### Step 3: Create the MCP Server File
**Show code creation process:**

1. **Import section** (lines 1-27)
```python
import asyncpg
from mcp.server import Server
from mcp.server.stdio import stdio_server
from mcp.types import Tool, TextContent
```
"These imports give us everything we need for MCP and database access"

2. **Database Pool** (lines 49-87)
```python
class DatabasePool:
    async def initialize(self):
        self.pool = await asyncpg.create_pool(
            self.database_url,
            min_size=2,
            max_size=10
        )
```
"Connection pooling reuses database connections for better performance"

3. **Server Instance** (line 91)
```python
app = Server("postgres-enterprise-mcp-server")
```
"This creates our MCP server instance"

4. **Tool Registration** (lines 94-354)
```python
@app.list_tools()
async def list_tools() -> list[Tool]:
    return [
        Tool(name="execute_select", ...),
        Tool(name="execute_insert", ...),
        # ... 11 more tools
    ]
```
"Claude discovers these tools automatically when it connects"

5. **Tool Handlers** (lines 357-727)
```python
@app.call_tool()
async def call_tool(name: str, arguments: Any):
    if name == "execute_select":
        result = await handle_select(arguments)
    # ... handle other tools
```
"Each tool call is routed to the appropriate handler"

#### Step 4: Configure Claude Desktop
**Show step-by-step:**

1. Locate config file:
   - Windows: `%APPDATA%\Claude\claude_desktop_config.json`
   - Mac: `~/Library/Application Support/Claude/claude_desktop_config.json`
   - Linux: `~/.config/Claude/claude_desktop_config.json`

2. Open with text editor (VS Code, Notepad++)

3. Add configuration:
```json
{
  "mcpServers": {
    "postgres-enterprise": {
      "command": "C:\\Users\\kusha\\postgresql-mcp\\.venv\\Scripts\\python.exe",
      "args": ["C:\\Users\\kusha\\postgresql-mcp\\mcp_server_enterprise.py"],
      "env": {
        "DATABASE_URL": "postgresql://pgadmina:Centurylink%40123@pgs-youtube-app.postgres.database.azure.com:5432/postgres?sslmode=require"
      }
    }
  }
}
```

4. **Validate JSON syntax** at jsonlint.com

5. Save file and completely close Claude Desktop

6. Restart Claude Desktop

**Show Claude Desktop:**
- Look for MCP indicator (small icon showing connected servers)
- Check status bar for confirmation

---

### 5. Feature Demonstrations (15-18 minutes)

#### Demo 1: Schema Inspection
**In Claude Desktop, type:**
```
"Show me all tables in my PostgreSQL database"
```

**Show Claude's response:**
- Lists all tables
- Shows tool usage: `get_schema_info`
- Displays structured data

**Behind the scenes code (show in editor):**
```python
async def handle_get_schema_info(arguments: dict) -> dict:
    tables_query = """
        SELECT schemaname, tablename
        FROM pg_catalog.pg_tables
        WHERE schemaname = $1
    """
    tables = await conn.fetch(tables_query, schema_name)
    # Returns structured schema information
```

#### Demo 2: Creating Tables (DDL)
**In Claude Desktop, type:**
```
"Create a table called 'habits' with these columns:
- id: serial primary key
- name: varchar(100), not null
- description: text
- frequency: varchar(20) with check constraint for 'daily', 'weekly', 'monthly'
- created_at: timestamp default now()
- user_id: integer with foreign key to users table"
```

**Show Claude:**
1. Analyzes the request
2. Calls `execute_create_table` tool
3. Generates SQL:
```sql
CREATE TABLE habits (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    description TEXT,
    frequency VARCHAR(20) CHECK (frequency IN ('daily', 'weekly', 'monthly')),
    created_at TIMESTAMP DEFAULT NOW(),
    user_id INTEGER REFERENCES users(id)
);
```
4. Executes and confirms success

**Verify in database:**
- Show pgAdmin or Azure portal query editor
- Run: `\d habits` or `SELECT * FROM information_schema.columns WHERE table_name = 'habits'`

#### Demo 3: Bulk Insert Operations
**In Claude Desktop, type:**
```
"Insert 5 sample habits into the habits table with realistic data"
```

**Show Claude:**
1. Generates INSERT with multiple VALUES
2. Uses `execute_insert` tool
3. Shows parameterized query for security

**Behind the scenes (explain in editor):**
```python
async def handle_insert(arguments: dict) -> dict:
    query = arguments.get("query")
    params = arguments.get("params", [])

    if "RETURNING" in query.upper():
        rows = await conn.fetch(query, *params)
        # Returns inserted data with new IDs
        return {"returned_data": [dict(row) for row in rows]}
```

**Example Claude generates:**
```sql
INSERT INTO habits (name, description, frequency, user_id) VALUES
    ('Morning Exercise', 'Run 5K', 'daily', 1),
    ('Read Books', 'Read for 30 minutes', 'daily', 1),
    ('Meal Prep', 'Prepare weekly meals', 'weekly', 1),
    ('Budget Review', 'Review finances', 'monthly', 1),
    ('Meditation', 'Mindfulness practice', 'daily', 1)
RETURNING id, name;
```

**Verify:**
```
"Show me all records from the habits table"
```

#### Demo 4: Complex Queries with JOINs
**In Claude Desktop, type:**
```
"Show me all habits with their user information, including user email and name. Order by created_at descending. Limit to 10 results."
```

**Show Claude generating:**
```sql
SELECT
    h.id,
    h.name AS habit_name,
    h.frequency,
    h.created_at,
    u.name AS user_name,
    u.email
FROM habits h
JOIN users u ON h.user_id = u.id
ORDER BY h.created_at DESC
LIMIT 10;
```

#### Demo 5: UPDATE Operations
**In Claude Desktop, type:**
```
"Update all habits with frequency 'daily' to have a description that says 'Performed daily'"
```

**Show:**
1. Claude calls `execute_update`
2. Generated SQL:
```sql
UPDATE habits
SET description = 'Performed daily'
WHERE frequency = 'daily';
```
3. Returns number of rows affected

**Then try parametrized update:**
```
"Change the frequency to 'weekly' for habit with id 3"
```

**Behind the scenes:**
```python
async def handle_update(arguments: dict) -> dict:
    query = "UPDATE habits SET frequency = $1 WHERE id = $2"
    params = ["weekly", 3]
    status = await conn.execute(query, *params)
    rows_affected = int(status.split()[-1])
```

#### Demo 6: Transactions (TCL)
**In Claude Desktop, type:**
```
"Create a new user named 'Alice' with email 'alice@example.com', then create 3 habits for her, all in a single transaction. If any operation fails, roll back everything."
```

**Show Claude:**
1. Recognizes need for transaction
2. Calls `execute_transaction` tool
3. Multiple statements executed atomically:

```sql
-- Statement 1
INSERT INTO users (name, email) VALUES ('Alice', 'alice@example.com') RETURNING id;

-- Statement 2
INSERT INTO habits (name, frequency, user_id) VALUES ('Morning Run', 'daily', [inserted_user_id]);

-- Statement 3
INSERT INTO habits (name, frequency, user_id) VALUES ('Evening Reading', 'daily', [inserted_user_id]);

-- Statement 4
INSERT INTO habits (name, frequency, user_id) VALUES ('Weekly Planning', 'weekly', [inserted_user_id]);
```

**Behind the scenes (show code):**
```python
async def handle_transaction(arguments: dict) -> dict:
    statements = arguments.get("statements", [])
    isolation_level = arguments.get("isolation_level", "read_committed")

    async with conn.transaction(isolation=isolation_level):
        for stmt in statements:
            query = stmt.get("query")
            params = stmt.get("params", [])
            # If any fails, entire transaction rolls back
            result = await conn.execute(query, *params)

    return {"success": True, "results": results}
```

**Demonstrate rollback:**
```
"Try to create a user with duplicate email and add habits. This should fail and rollback."
```
Show the error and confirm no partial data was inserted.

#### Demo 7: ALTER TABLE (Schema Changes)
**In Claude Desktop, type:**
```
"Add a new column 'priority' (integer, default 1) to the habits table"
```

**Show:**
```sql
ALTER TABLE habits ADD COLUMN priority INTEGER DEFAULT 1;
```

**Then:**
```
"Add an index on the frequency column for faster queries"
```

```sql
CREATE INDEX idx_habits_frequency ON habits(frequency);
```

#### Demo 8: DELETE Operations with Safety
**In Claude Desktop, type:**
```
"Delete all habits where created_at is older than 30 days"
```

**Show:**
1. Claude generates safe WHERE clause
2. Returns count of deleted rows
3. Confirm with verification query

#### Demo 9: Advanced: Aggregate Queries
**In Claude Desktop, type:**
```
"Show me statistics: count of habits grouped by frequency, with average user_id"
```

**Show Claude generating:**
```sql
SELECT
    frequency,
    COUNT(*) as habit_count,
    AVG(user_id) as avg_user_id
FROM habits
GROUP BY frequency
ORDER BY habit_count DESC;
```

#### Demo 10: Raw SQL for Complex Operations
**In Claude Desktop, type:**
```
"Show me the database size and table sizes for all tables"
```

**Show:**
```sql
SELECT
    schemaname,
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS size
FROM pg_tables
WHERE schemaname = 'public'
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;
```

---

### 6. Security Best Practices (5-6 minutes)

#### 1. Database User Permissions
**Show in pgAdmin or Azure query editor:**

```sql
-- Create dedicated MCP user
CREATE USER mcp_user WITH PASSWORD 'SecureP@ssw0rd!2024';

-- Grant minimal permissions
GRANT CONNECT ON DATABASE postgres TO mcp_user;
GRANT USAGE ON SCHEMA public TO mcp_user;

-- DML only (safer)
GRANT SELECT, INSERT, UPDATE, DELETE ON ALL TABLES IN SCHEMA public TO mcp_user;

-- Only add DDL if needed
-- GRANT CREATE ON SCHEMA public TO mcp_user;

-- For new tables
ALTER DEFAULT PRIVILEGES IN SCHEMA public
GRANT SELECT, INSERT, UPDATE, DELETE ON TABLES TO mcp_user;
```

**Explain:**
- "Never use admin credentials for MCP"
- "Principle of least privilege"
- "Separate users for development vs production"

#### 2. Parameterized Queries (SQL Injection Prevention)
**Show code example:**

**WRONG (Vulnerable):**
```python
# âŒ DON'T DO THIS - SQL Injection risk
query = f"SELECT * FROM users WHERE email = '{email}'"
```

**RIGHT (Safe):**
```python
# âœ… DO THIS - Parameterized query
query = "SELECT * FROM users WHERE email = $1"
params = [email]
await conn.fetch(query, *params)
```

**Demonstrate attack prevention:**
- "If user inputs: `'; DROP TABLE users; --`"
- "Parameterized query treats this as literal string"
- "asyncpg handles escaping automatically"

#### 3. Environment Variables & Secrets
**Show:**
```python
# .env file (NEVER commit to git)
DATABASE_URL=postgresql://user:pass@host/db

# .gitignore
.env
.env.local
*.env
```

**Best practices:**
- Use Azure Key Vault or AWS Secrets Manager
- Rotate credentials regularly
- Different credentials per environment
- Monitor access logs

#### 4. Connection Security
**Show configuration:**
```python
DATABASE_URL=postgresql://user:pass@host:5432/db?sslmode=require
                                                    ^^^^^^^^^^^^^^^^
```

**Explain:**
- `sslmode=require` - Enforces encrypted connections
- Azure/RDS require SSL by default
- Never allow `sslmode=disable` in production

#### 5. Audit Logging
**Show PostgreSQL logging:**
```sql
-- Enable query logging
ALTER SYSTEM SET log_statement = 'mod';  -- Log INSERT, UPDATE, DELETE
ALTER SYSTEM SET log_min_duration_statement = 1000;  -- Log slow queries

-- Reload configuration
SELECT pg_reload_conf();

-- View logs
SELECT * FROM pg_stat_statements;
```

#### 6. Network Security (Azure)
**Show in Azure Portal:**
1. Firewall rules â†’ Add specific IPs only
2. Virtual Network integration
3. Private endpoints for VPN access
4. Deny public access option

---

### 7. Comparison with Standard MCP (3-4 minutes)

**Show side-by-side table:**

| Feature | Standard @modelcontextprotocol/server-postgres | This Enterprise Server |
|---------|-----------------------------------------------|----------------------|
| SELECT queries | âœ… Read-only | âœ… Full support with JOINs |
| INSERT operations | âŒ No | âœ… Yes with RETURNING |
| UPDATE operations | âŒ No | âœ… Yes |
| DELETE operations | âŒ No | âœ… Yes |
| CREATE TABLE | âŒ No | âœ… Yes |
| ALTER TABLE | âŒ No | âœ… Yes |
| DROP TABLE | âŒ No | âœ… Yes with CASCADE |
| Transactions | âŒ No | âœ… Yes with isolation levels |
| Bulk operations | âŒ Limited | âœ… Optimized with asyncpg |
| Connection pooling | âŒ No | âœ… Yes (2-10 connections) |
| Parameterized queries | âœ… Yes | âœ… Yes |
| Error handling | âš ï¸ Basic | âœ… Comprehensive |
| Language | TypeScript | Python |

**Key advantages:**
- "Full database control vs read-only"
- "Production-ready with connection pooling"
- "Transaction support for data integrity"
- "Better error handling and logging"

---

### 8. Troubleshooting Common Issues (4-5 minutes)

#### Issue 1: "MCP Server Not Showing in Claude Desktop"
**Solutions:**
```bash
# 1. Validate JSON config
# Use https://jsonlint.com

# 2. Check config file location
# Windows: Win+R â†’ %APPDATA%\Claude

# 3. Verify Python path
C:\Users\kusha\postgresql-mcp\.venv\Scripts\python.exe --version

# 4. Test server standalone
cd C:\Users\kusha\postgresql-mcp
.venv\Scripts\activate
python mcp_server_enterprise.py

# 5. Check Claude logs
# Windows: %APPDATA%\Claude\logs
```

#### Issue 2: "Database Connection Failed"
**Solutions:**
```bash
# 1. Test connection with asyncpg
python
>>> import asyncpg
>>> import asyncio
>>> async def test():
...     conn = await asyncpg.connect('postgresql://...')
...     print(await conn.fetchval('SELECT version()'))
>>> asyncio.run(test())

# 2. Check Azure firewall
# Azure Portal â†’ PostgreSQL â†’ Connection security â†’ Add current IP

# 3. Verify SSL mode
# Try with sslmode=require, then sslmode=prefer

# 4. Test with psql
psql "postgresql://user:pass@host:5432/db?sslmode=require"
```

#### Issue 3: "Module Not Found Errors"
**Solutions:**
```bash
# Activate virtual environment first
.venv\Scripts\activate  # Windows
source .venv/bin/activate  # Linux/Mac

# Reinstall dependencies
pip install --upgrade -r requirements.txt

# Verify installation
pip list | grep mcp
pip list | grep asyncpg

# Check Python version (3.8+ required)
python --version
```

#### Issue 4: "Permission Denied on Database Operations"
**Solutions:**
```sql
-- Check current permissions
SELECT * FROM information_schema.table_privileges
WHERE grantee = 'mcp_user';

-- Grant missing permissions
GRANT INSERT, UPDATE ON TABLE habits TO mcp_user;

-- Check role memberships
\du mcp_user
```

#### Issue 5: "Transaction Deadlocks"
**Solutions:**
```python
# Add retry logic
async def handle_transaction_with_retry(arguments: dict, max_retries=3):
    for attempt in range(max_retries):
        try:
            return await handle_transaction(arguments)
        except asyncpg.exceptions.DeadlockDetectedError:
            if attempt == max_retries - 1:
                raise
            await asyncio.sleep(0.1 * (2 ** attempt))  # Exponential backoff
```

---

### 9. Advanced Features & Extensions (5-6 minutes)

#### Extension 1: Multiple Database Support
**Show configuration:**
```json
{
  "mcpServers": {
    "postgres-production": {
      "command": "python",
      "args": ["mcp_server_enterprise.py"],
      "env": {
        "DATABASE_URL": "postgresql://user:pass@prod-host/prod_db"
      }
    },
    "postgres-staging": {
      "command": "python",
      "args": ["mcp_server_enterprise.py"],
      "env": {
        "DATABASE_URL": "postgresql://user:pass@staging-host/staging_db"
      }
    },
    "postgres-development": {
      "command": "python",
      "args": ["mcp_server_enterprise.py"],
      "env": {
        "DATABASE_URL": "postgresql://user:pass@localhost/dev_db"
      }
    }
  }
}
```

**In Claude Desktop:**
```
"Show me all tables in postgres-production"
"Compare table counts between production and staging"
```

#### Extension 2: Custom Tool - Backup Tables
**Show adding new tool:**

```python
# In list_tools()
Tool(
    name="backup_table",
    description="Create a backup copy of a table with timestamp",
    inputSchema={
        "type": "object",
        "properties": {
            "table_name": {"type": "string"},
            "backup_suffix": {"type": "string", "default": "backup"}
        },
        "required": ["table_name"]
    }
)

# Handler
async def handle_backup_table(arguments: dict) -> dict:
    table_name = arguments.get("table_name")
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    backup_name = f"{table_name}_backup_{timestamp}"

    async with db_manager.acquire() as conn:
        query = f"CREATE TABLE {backup_name} AS SELECT * FROM {table_name}"
        await conn.execute(query)

        count_query = f"SELECT COUNT(*) FROM {backup_name}"
        count = await conn.fetchval(count_query)

        return {
            "success": True,
            "backup_table": backup_name,
            "rows_copied": count
        }
```

#### Extension 3: Query Performance Analysis
**Add tool:**
```python
Tool(
    name="analyze_query_performance",
    description="Get EXPLAIN ANALYZE output for a query",
    inputSchema={
        "type": "object",
        "properties": {
            "query": {"type": "string"}
        }
    }
)

async def handle_analyze_query(arguments: dict) -> dict:
    query = arguments.get("query")
    explain_query = f"EXPLAIN (ANALYZE, BUFFERS, FORMAT JSON) {query}"

    async with db_manager.acquire() as conn:
        result = await conn.fetchval(explain_query)
        return {
            "success": True,
            "execution_plan": result
        }
```

**Use in Claude:**
```
"Analyze the performance of this query: SELECT * FROM habits WHERE user_id = 5"
```

#### Extension 4: Data Export to CSV
**Add tool:**
```python
Tool(
    name="export_to_csv",
    description="Export query results to CSV file",
    inputSchema={
        "type": "object",
        "properties": {
            "query": {"type": "string"},
            "output_file": {"type": "string"}
        }
    }
)

async def handle_export_csv(arguments: dict) -> dict:
    query = arguments.get("query")
    output_file = arguments.get("output_file")

    async with db_manager.acquire() as conn:
        rows = await conn.fetch(query)

        import csv
        with open(output_file, 'w', newline='') as f:
            if rows:
                writer = csv.DictWriter(f, fieldnames=rows[0].keys())
                writer.writeheader()
                writer.writerows([dict(row) for row in rows])

        return {
            "success": True,
            "file": output_file,
            "rows_exported": len(rows)
        }
```

---

### 10. Production Deployment Considerations (4-5 minutes)

#### Docker Containerization
**Show Dockerfile:**
```dockerfile
FROM python:3.11-slim

WORKDIR /app

# Install dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application
COPY mcp_server_enterprise.py .

# Create non-root user
RUN useradd -m -u 1000 mcpuser && chown -R mcpuser:mcpuser /app
USER mcpuser

# Run server
CMD ["python", "mcp_server_enterprise.py"]
```

**Build and run:**
```bash
docker build -t postgres-mcp-server .
docker run -e DATABASE_URL="postgresql://..." postgres-mcp-server
```

#### Environment-Specific Configurations
**Show .env files:**
```bash
# .env.development
DATABASE_URL=postgresql://localhost/dev_db
LOG_LEVEL=DEBUG

# .env.staging
DATABASE_URL=postgresql://staging-host/staging_db
LOG_LEVEL=INFO

# .env.production
DATABASE_URL=postgresql://prod-host/prod_db
LOG_LEVEL=WARNING
```

**Load based on environment:**
```python
import os
from dotenv import load_dotenv

env = os.getenv("ENVIRONMENT", "development")
load_dotenv(f".env.{env}")
```

#### Health Checks & Monitoring
**Add health check endpoint:**
```python
@app.get("/health")
async def health_check():
    try:
        async with db_manager.acquire() as conn:
            await conn.fetchval("SELECT 1")
        return {"status": "healthy", "database": "connected"}
    except Exception as e:
        return {"status": "unhealthy", "error": str(e)}
```

#### Rate Limiting
**Add rate limiting:**
```python
from collections import defaultdict
from datetime import datetime, timedelta

rate_limits = defaultdict(list)

async def check_rate_limit(user_id: str, max_requests: int = 100, window: int = 60):
    now = datetime.now()
    cutoff = now - timedelta(seconds=window)

    # Remove old requests
    rate_limits[user_id] = [req_time for req_time in rate_limits[user_id] if req_time > cutoff]

    if len(rate_limits[user_id]) >= max_requests:
        raise Exception("Rate limit exceeded")

    rate_limits[user_id].append(now)
```

---

### 11. Real-World Use Cases (3-4 minutes)

#### Use Case 1: Data Analysis with Claude
**Scenario:** "Analyze our user behavior"
```
User: "Show me the top 10 most active users based on habit completion count"

Claude: Executes complex query with JOINs and aggregations
Returns insights and visualizations
```

#### Use Case 2: Database Maintenance
**Scenario:** "Clean up old data"
```
User: "Delete all habits from users who haven't logged in for 90 days"

Claude:
1. Finds inactive users
2. Backs up data
3. Deletes in transaction
4. Confirms results
```

#### Use Case 3: Schema Evolution
**Scenario:** "Add new feature"
```
User: "We need to track habit streaks. Add a streak counter to habits table"

Claude:
1. Adds streak_count column
2. Creates trigger to update streaks
3. Initializes values for existing records
4. Creates index for performance
```

#### Use Case 4: Reporting & Analytics
**Scenario:** "Generate monthly report"
```
User: "Create a summary of habit completions by category for last month"

Claude:
1. Writes complex aggregation query
2. Groups by category
3. Calculates percentages
4. Exports to format you need
```

---

### 12. Conclusion & Next Steps (2-3 minutes)

**Recap:**
âœ… Built enterprise-grade MCP server for PostgreSQL
âœ… Integrated with Claude Desktop
âœ… Demonstrated full DDL, DML, TCL operations
âœ… Covered security best practices
âœ… Showed real-world use cases

**What You Learned:**
1. MCP protocol fundamentals
2. Python asyncpg for PostgreSQL
3. Connection pooling & performance
4. Claude Desktop integration
5. Security hardening
6. Production deployment

**Next Steps:**
1. **Expand your server:**
   - Add custom tools for your use case
   - Implement caching layer
   - Add audit logging
   - Create backup automation

2. **Explore other MCP servers:**
   - File system access
   - REST API integration
   - Browser automation
   - Git operations

3. **Build your own MCP servers:**
   - MongoDB, MySQL, Redis
   - AWS, Azure, GCP integrations
   - Custom business logic

**Resources:**
- ðŸ“– Full documentation: `MCP_README.md`
- ðŸ”§ Setup guide: `SETUP_GUIDE.md`
- ðŸ’» Source code: GitHub repository
- ðŸ“š MCP specification: anthropic.com/docs/mcp
- ðŸ’¬ Community: Discord/Forum links

**Call to Action:**
- â­ Star the GitHub repository
- ðŸ’¬ Share your use cases in comments
- ðŸš€ Deploy your own MCP server
- ðŸ“§ Subscribe for more AI/database tutorials

---

## ðŸŽ¬ Production Tips

### Filming Setup:
1. **Screen Recording:**
   - Use OBS Studio or Camtasia
   - 1920x1080 resolution minimum
   - 60fps for smooth animations
   - Record terminal, IDE, and browser separately

2. **Code Editor Settings:**
   - Use high-contrast theme (Dark+ or Dracula)
   - Font size: 16-18pt
   - Enable line numbers
   - Highlight syntax clearly

3. **Terminal Settings:**
   - Use Windows Terminal or iTerm2
   - Font size: 14-16pt
   - Color scheme: Solarized Dark or One Dark
   - Clear prompt (PS1 variable)

4. **Audio:**
   - Use decent USB microphone
   - Record in quiet room
   - Post-process: noise reduction, normalization

### Editing:
1. **Add captions** for complex commands
2. **Zoom in** on important code sections
3. **Use callouts** to highlight key points
4. **Add chapter markers** for each section
5. **Include timestamps** in video description

### Graphics to Include:
1. Architecture diagram
2. MCP protocol flow
3. Security checklist
4. Comparison table
5. Troubleshooting flowchart

---

## ðŸ“ Video Description Template

```
ðŸš€ Build an Enterprise PostgreSQL MCP Server for Claude Desktop | Complete Tutorial

Learn how to create a production-grade Model Context Protocol (MCP) server that gives Claude Desktop full control over your PostgreSQL database through natural language!

â±ï¸ TIMESTAMPS:
00:00 - Introduction
02:30 - What is MCP?
06:45 - Project Architecture
11:20 - Azure PostgreSQL Setup
21:35 - MCP Server Development
36:50 - Claude Desktop Integration
42:15 - Feature Demonstrations
57:30 - Security Best Practices
1:02:45 - Troubleshooting
1:07:20 - Advanced Features
1:12:50 - Production Deployment
1:17:30 - Real-World Use Cases
1:21:00 - Conclusion

ðŸ”— RESOURCES:
ðŸ“¦ GitHub Repository: [your-repo-link]
ðŸ“– Documentation: [docs-link]
ðŸ˜ Azure PostgreSQL: https://azure.microsoft.com/postgresql
ðŸ¤– MCP Specification: https://anthropic.com/mcp

ðŸ’» WHAT YOU'LL BUILD:
âœ… Full DDL operations (CREATE, ALTER, DROP tables)
âœ… Complete DML support (SELECT, INSERT, UPDATE, DELETE)
âœ… Transaction control (ACID compliance)
âœ… Connection pooling for performance
âœ… Parameterized queries for security
âœ… Bulk operations support
âœ… Claude Desktop integration

ðŸŽ¯ WHO THIS IS FOR:
- Python developers
- Database administrators
- AI/ML engineers
- Backend developers
- DevOps engineers

ðŸ› ï¸ PREREQUISITES:
- Python 3.8+
- Basic SQL knowledge
- Claude Desktop account
- Azure account (or local PostgreSQL)

ðŸ“š TOPICS COVERED:
#MCP #PostgreSQL #Claude #AI #Python #Database #Azure #CloudComputing #Tutorial #Programming

ðŸ’¬ Let me know in the comments what MCP server you want to see next!

ðŸ”” Subscribe for more AI and database tutorials!
```

---

## ðŸŽ¨ Thumbnail Ideas

**Option 1: Split screen**
- Left: Claude Desktop interface
- Right: PostgreSQL database diagram
- Center: "MCP" logo/text
- Bottom: "Full Tutorial"

**Option 2: Architecture diagram**
- Three layers (Claude â†’ MCP â†’ PostgreSQL)
- Arrows showing data flow
- Bold text: "Natural Language to SQL"

**Option 3: Code + Results**
- Top: Natural language query
- Middle: Generated SQL
- Bottom: Results table
- Badge: "Production Ready"

---

## âœ… Pre-Launch Checklist

**Code Preparation:**
- [ ] All files properly formatted
- [ ] Remove sensitive credentials
- [ ] Add comments for clarity
- [ ] Test all features one final time
- [ ] Create GitHub repository

**Recording:**
- [ ] Test screen recording setup
- [ ] Check audio levels
- [ ] Prepare clean desktop
- [ ] Close unnecessary applications
- [ ] Have all terminals/windows ready

**Content:**
- [ ] Script reviewed
- [ ] Timing estimated
- [ ] Examples tested
- [ ] Backup recordings of demos
- [ ] Graphics prepared

**Post-Production:**
- [ ] Edit video
- [ ] Add captions
- [ ] Create thumbnail
- [ ] Write description
- [ ] Prepare pinned comment
- [ ] Schedule upload

---

## ðŸŽ¤ Speaking Tips

1. **Pace yourself** - Don't rush through complex concepts
2. **Use analogies** - Compare to familiar concepts
3. **Repeat key points** - Emphasize important takeaways
4. **Show enthusiasm** - Your energy translates to viewers
5. **Pause for effect** - Let important points sink in
6. **Correct mistakes** - If you make an error, acknowledge and fix it
7. **Engage viewers** - Ask questions, prompt comments

---

## ðŸ“Š Success Metrics

**Track these metrics:**
- View duration (aim for >50% average view duration)
- Engagement rate (likes, comments, shares)
- Click-through rate on thumbnail
- GitHub repository stars/forks
- Comment questions (shows interest)

**Improve based on:**
- Timestamp analytics (where people drop off)
- Common questions in comments
- Requests for follow-up content

---

## ðŸ”„ Follow-Up Content Ideas

**Video Series:**
1. "Building Custom MCP Servers - MongoDB Edition"
2. "MCP Server Performance Optimization"
3. "Deploying MCP Servers to Production"
4. "MCP Security Deep Dive"
5. "Building MCP Servers for AWS/GCP"

**Blog Posts:**
- "MCP Server Best Practices"
- "Troubleshooting MCP Integrations"
- "MCP vs REST APIs: When to Use What"

---

Good luck with your YouTube presentation! This comprehensive guide should help you create an excellent tutorial that viewers can follow along with. ðŸš€
